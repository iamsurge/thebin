from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
# web driver manager: https://github.com/SergeyPirogov/webdriver_manager
# will help us automatically download the web driver binaries
# then we can use `Service` to manage the web driver's state.
from webdriver_manager.chrome import ChromeDriverManager

# this part was done before
options = webdriver.ChromeOptions()
options.headless = True
chrome_path = ChromeDriverManager().install()
chrome_service = Service(chrome_path)
driver = webdriver.Chrome(service=chrome_service, options=options)


url = "https://www.scrapethissite.com/pages/"
 
driver.get(url)

extracted_data = []
pages = driver.find_elements(By.CSS_SELECTOR, "div.page")

for page in pages:
    title = page.find_element(By.TAG_NAME, "h3").text.strip()
    link = page.find_element(By.TAG_NAME, "a").get_attribute("href")
    description = page.find_element(By.TAG_NAME, "p").text.strip()

    data = {"title": title, "link": link, "description": description}
    extracted_data.append(data)

for data in extracted_data:
    print(data)

driver.quit()